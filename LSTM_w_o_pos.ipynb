{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Achraf-Trabelsi/PFA-NLP/blob/main/LSTM_w_o_pos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpmAzfuB_N-B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7b1c74f-86a8-43d9-fcab-e650f39e3dcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Downloading feedback-prize-2021.zip to /content\n",
            " 77% 25.0M/32.4M [00:00<00:00, 55.0MB/s]\n",
            "100% 32.4M/32.4M [00:00<00:00, 63.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Mount the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/drive/MyDrive/PFA/data/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle competitions download -c feedback-prize-2021\n",
        "!mkdir /content/data\n",
        "!unzip -q -n feedback-prize-2021.zip -d /content/data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lySfByMO_MNX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "9c0ea3f1-080f-44ac-da8b-923056cdb866"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id  discourse_id  discourse_start  discourse_end  \\\n",
              "0  423A1CA112E2  1.622628e+12              8.0          229.0   \n",
              "1  423A1CA112E2  1.622628e+12            230.0          312.0   \n",
              "2  423A1CA112E2  1.622628e+12            313.0          401.0   \n",
              "3  423A1CA112E2  1.622628e+12            402.0          758.0   \n",
              "4  423A1CA112E2  1.622628e+12            759.0          886.0   \n",
              "\n",
              "                                      discourse_text discourse_type  \\\n",
              "0  Modern humans today are always on their phone....           Lead   \n",
              "1  They are some really bad consequences when stu...       Position   \n",
              "2  Some certain areas in the United States ban ph...       Evidence   \n",
              "3  When people have phones, they know about certa...       Evidence   \n",
              "4  Driving is one of the way how to get around. P...          Claim   \n",
              "\n",
              "  discourse_type_num                                   predictionstring  \n",
              "0             Lead 1  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...  \n",
              "1         Position 1       45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  \n",
              "2         Evidence 1    60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  \n",
              "3         Evidence 2  76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...  \n",
              "4            Claim 1  139 140 141 142 143 144 145 146 147 148 149 15...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5c1c8e9d-7cdf-4e8a-bd65-96f0a338ec7a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>discourse_id</th>\n",
              "      <th>discourse_start</th>\n",
              "      <th>discourse_end</th>\n",
              "      <th>discourse_text</th>\n",
              "      <th>discourse_type</th>\n",
              "      <th>discourse_type_num</th>\n",
              "      <th>predictionstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>8.0</td>\n",
              "      <td>229.0</td>\n",
              "      <td>Modern humans today are always on their phone....</td>\n",
              "      <td>Lead</td>\n",
              "      <td>Lead 1</td>\n",
              "      <td>1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>230.0</td>\n",
              "      <td>312.0</td>\n",
              "      <td>They are some really bad consequences when stu...</td>\n",
              "      <td>Position</td>\n",
              "      <td>Position 1</td>\n",
              "      <td>45 46 47 48 49 50 51 52 53 54 55 56 57 58 59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>313.0</td>\n",
              "      <td>401.0</td>\n",
              "      <td>Some certain areas in the United States ban ph...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Evidence 1</td>\n",
              "      <td>60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>402.0</td>\n",
              "      <td>758.0</td>\n",
              "      <td>When people have phones, they know about certa...</td>\n",
              "      <td>Evidence</td>\n",
              "      <td>Evidence 2</td>\n",
              "      <td>76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 9...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>423A1CA112E2</td>\n",
              "      <td>1.622628e+12</td>\n",
              "      <td>759.0</td>\n",
              "      <td>886.0</td>\n",
              "      <td>Driving is one of the way how to get around. P...</td>\n",
              "      <td>Claim</td>\n",
              "      <td>Claim 1</td>\n",
              "      <td>139 140 141 142 143 144 145 146 147 148 149 15...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c1c8e9d-7cdf-4e8a-bd65-96f0a338ec7a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5c1c8e9d-7cdf-4e8a-bd65-96f0a338ec7a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5c1c8e9d-7cdf-4e8a-bd65-96f0a338ec7a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os \n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "path='/content/data/'\n",
        "data=pd.read_csv(f'{path}train.csv')\n",
        "data.head()\n",
        "data.sort_values('id')\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWIbfs2y_MNa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e42ebe3d-61c0-41cd-d532-01c9f60f543e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/state_union.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.corpus import state_union\n",
        "from nltk.tokenize import PunktSentenceTokenizer\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('state_union')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4zb2JiH_MNa"
      },
      "outputs": [],
      "source": [
        "sample_text = state_union.raw(\"2006-GWBush.txt\")\n",
        "train_text  = state_union.raw(\"2005-GWBush.txt\") \n",
        "custom_sent_tokenizer = PunktSentenceTokenizer(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsKvJ5zo_MNb"
      },
      "outputs": [],
      "source": [
        "tokenized = custom_sent_tokenizer.tokenize(sample_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4J1DkqWqJWrl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c0b25ea-32ea-4aaa-ab53-af2afd52839d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'O', 1: 'Lead', 2: 'Position', 3: 'Evidence', 4: 'Claim', 5: 'Concluding Statement', 6: 'Counterclaim', 7: 'Rebuttal'}\n"
          ]
        }
      ],
      "source": [
        "def make_tag_lookup_table():\n",
        "    labels = list(pd.unique(data['discourse_type'].values))\n",
        "    labels = ['O'] + labels\n",
        "    return dict(zip(range(0,len(labels)+1),labels))\n",
        "\n",
        "mapping = make_tag_lookup_table()\n",
        "print(mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8byD17I8_MNc"
      },
      "outputs": [],
      "source": [
        "def tagged_text(data,size):\n",
        "        path='/content/data'\n",
        "        mapping = make_tag_lookup_table()\n",
        "        k=0\n",
        "        df=pd.DataFrame(columns=['id','text','POS tags','Arg tags'])\n",
        "        ids=pd.unique(data['id'].values)[:]\n",
        "        for id in ids:\n",
        "            k=k + 1\n",
        "            if k % 1000 == 0:\n",
        "                print(f'{k} \\n')\n",
        "            try:\n",
        "                f=open(path+'/train/'+id+'.txt','r')\n",
        "                tagged_list=[]\n",
        "                text=f.read()\n",
        "                tokenized = custom_sent_tokenizer.tokenize(text)\n",
        "                for i in tokenized:\n",
        "                    words = i.split()\n",
        "                    tagged = nltk.pos_tag(words)\n",
        "                    tagged_list.extend(tagged)\n",
        "\n",
        "                arg_tags= np.zeros(len(text.split()),dtype=float)\n",
        "                for (key,tag) in mapping.items():\n",
        "                    for prediction in data.loc[(data['id']==id) & (data['discourse_type']==tag),'predictionstring']:\n",
        "                        pred_array=list(map(int, prediction.split()))\n",
        "                        arg_tags[pred_array]=key\n",
        "                df=df.append({'id':id, 'text': text, 'POS tags': tagged_list,'Arg tags': arg_tags}, ignore_index=True)\n",
        "            except Exception as e:\n",
        "                print(str(e))\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SqMqV_Xj_MNd",
        "outputId": "f47ae0f2-bccc-4643-a616-264506ad2fa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000 \n",
            "\n",
            "2000 \n",
            "\n",
            "3000 \n",
            "\n",
            "4000 \n",
            "\n",
            "5000 \n",
            "\n",
            "6000 \n",
            "\n",
            "7000 \n",
            "\n",
            "8000 \n",
            "\n",
            "9000 \n",
            "\n",
            "10000 \n",
            "\n",
            "11000 \n",
            "\n",
            "12000 \n",
            "\n",
            "13000 \n",
            "\n",
            "14000 \n",
            "\n",
            "15000 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "df = tagged_text(data,5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Kwua25k_MNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "787f9da3-1b39-4a9e-d3b2-391b2a82998d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "max_seq_length = max(len(x) for x in df['Arg tags'].values)\n",
        "max_seq_length=800\n",
        "print(max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zvgrNEub_MNf"
      },
      "outputs": [],
      "source": [
        "def write_train_files(df):\n",
        "    ids=df['id'].values\n",
        "    corpus_size=len(ids)\n",
        "    for  i in range(0,corpus_size):\n",
        "      id = ids[i]\n",
        "      tok = [x[0] for x in df['POS tags'][i]]\n",
        "      pos = [x[1] for x in df['POS tags'][i]]\n",
        "      arg = df['Arg tags'][i]\n",
        "      path='data'\n",
        "      if len(pos) == len(arg):\n",
        "        l=len(pos)\n",
        "      else:\n",
        "        l = min(len(pos),len(arg)) \n",
        "      try:\n",
        "          with open(f'{path}/train_data/{id}.txt', 'a') as the_file:\n",
        "\n",
        "              for j in range(0,l):\n",
        "                t = tok[j]\n",
        "                p = pos[j]\n",
        "                a = arg[j]\n",
        "                the_file.write(f'{t} {p} {a}\\n')\n",
        "      except FileNotFoundError as e:\n",
        "          os.system(f'mkdir {path}/train_data/')\n",
        "          the_file=open(f'{path}/train_data/{id}.txt', 'x')\n",
        "          for j in range(0,l):\n",
        "              t = tok[j]\n",
        "              p = pos[j]\n",
        "              a = arg[j]\n",
        "              the_file.write(f'{t} {p} {a}\\n')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EasbGLXH_MNg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0a9fcc9-0c35-4b04-feb7-a6e01bdf7182"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/data/train_data/*': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!rm /content/data/train_data/*\n",
        "write_train_files(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4n3ypM88X0L"
      },
      "outputs": [],
      "source": [
        "#!cat /content/data/train_data/E05C7F5C1156.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpH9f_CtsoEm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0478e8-e8ad-4892-e0d2-996f14623cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-02 12:53:03--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2022-06-02 12:53:04--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2022-06-02 12:53:04--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.08MB/s    in 2m 40s  \n",
            "\n",
            "2022-06-02 12:55:44 (5.13 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import urllib.request\n",
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q -n \"/content/glove.6B.zip\" -d \"/content/\"\n",
        "emmbed_dict = {}\n",
        "with open('/content/glove.6B.50d.txt','r') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:],'float32')\n",
        "    emmbed_dict[word]=vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MBfDPgnb36Pb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5826faec-7011-4f49-8f36-b5dfc95b0c44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]   Unzipping help/tagsets.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['LS', 'TO', 'VBN', \"''\", 'WP', 'UH', 'VBG', 'JJ', 'VBZ', '--', 'VBP', 'NN', 'DT', 'PRP', ':', 'WP$', 'NNPS', 'PRP$', 'WDT', '(', ')', '.', ',', '``', '$', 'RB', 'RBR', 'RBS', 'VBD', 'IN', 'FW', 'RP', 'JJR', 'JJS', 'PDT', 'MD', 'VB', 'WRB', 'NNP', 'EX', 'NNS', 'SYM', 'CC', 'CD', 'POS'])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.data import load\n",
        "nltk.download('tagsets')\n",
        "tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
        "tagdict.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_apTWlexthou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8be812d-526a-49cf-a195-b4b9bcbcb73b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50,)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "emmbed_dict['feel'].shape"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings_index = dict()\n",
        "f = open('/content/glove.6B.50d.txt')\n",
        "for line in f:\n",
        "\tvalues = line.split()\n",
        "\tword = values[0]\n",
        "\tcoefs = np.asarray(values[1:], dtype='float32')\n",
        "\tembeddings_index[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "id": "GBaoMFIqD4i_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lTxCp51tKNI"
      },
      "outputs": [],
      "source": [
        "from numpy.ma.core import empty\n",
        "import re\n",
        "import nltk\n",
        "from nltk.data import load\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "import csv\n",
        "\n",
        "\n",
        "def pos_lookup_table():\n",
        "  tagdict = load('help/tagsets/upenn_tagset.pickle')\n",
        "  pos_dict=dict()\n",
        "  i=0\n",
        "  pos_dict['0']=0\n",
        "  for key in tagdict.keys():\n",
        "    i=i+1\n",
        "    pos_dict[key]=i\n",
        "\n",
        "  return pos_dict\n",
        "\n",
        "def wordNormalize(word):\n",
        "    word = word.lower()\n",
        "    word = word.replace(\"--\", \"-\")\n",
        "    word = re.sub(\"\\\"+\", '\"', word)\n",
        "    word = re.sub(\"[0-9]{4}-[0-9]{2}-[0-9]{2}\", '0', word)\n",
        "    word = re.sub(\"[0-9]{2}:[0-9]{2}:[0-9]{2}\", '0', word)\n",
        "    word = re.sub(\"[0-9]{2}:[0-9]{2}\", '0', word)\n",
        "    word = re.sub(\"[0-9.,]+\", '0', word)\n",
        "    return word\n",
        "  \n",
        "def create_dataset(emmbed_dim, max_words):\n",
        "  try: \n",
        "    fi=open(f'/content/data/dataset.csv', 'x')\n",
        "    writer=csv.writer(fi,delimiter=',',lineterminator='\\n')\n",
        "    writer.writerow(['id','text','pos', 'arg'])\n",
        "    fi.close()\n",
        "  except Exception as e:\n",
        "    os.system('rm /content/data/dataset.csv')\n",
        "    fi=open(f'/content/data/dataset.csv', 'x')\n",
        "    writer=csv.writer(fi,delimiter=',',lineterminator='\\n')\n",
        "    writer.writerow(['id','text','pos', 'arg'])\n",
        "    fi.close()\n",
        "  \n",
        "  #dataset=pd.DataFrame(columns=['id','text','POS tags','Arg tags'])\n",
        "  pos_dict=pos_lookup_table()\n",
        "  for files in os.listdir('/content/data/train_data'): \n",
        "    id = files.strip('.txt')\n",
        "\n",
        "    word_count=0\n",
        "    with open(f'/content/data/train_data/{files}','r') as f:\n",
        "      #docVec=np.empty(shape=(max_words, emmbed_dim))\n",
        "      doc = str()\n",
        "      pos_tag_vec=[]\n",
        "      arg_tag_vec=[]\n",
        "      for line in f:\n",
        "        splits = line.strip().split()\n",
        "        if len(splits) > 1:\n",
        "          word = splits[0]\n",
        "          if word_count == max_words :\n",
        "            break;\n",
        "          word_count=word_count+1\n",
        "          wordLower = word.lower()\n",
        "          wordNorm = wordNormalize(wordLower)\n",
        "\n",
        "          #wordVec=np.reshape(wordVec,newshape=(emmbed_dim,1)).T\n",
        "          pos_tag = splits[1]\n",
        "          try:\n",
        "            pos_tag_code = pos_dict[pos_tag]\n",
        "          except Exception as e:\n",
        "            pos_tag_code = -1\n",
        "          \n",
        "          arg_tag = splits[2]\n",
        "         \n",
        "          doc = doc + ' ' + wordNorm\n",
        "          pos_tag_vec.append(pos_tag_code)\n",
        "          arg_tag_vec.append(arg_tag)\n",
        "\n",
        "      #docVec = np.delete(docVec,[range(0,max_words)], axis=0)\n",
        "      #pos_tag_vec = np.delete(pos_tag_vec,range(0,max_words))\n",
        "      #arg_tag_vec = np.delete(arg_tag_vec,range(0,max_words))\n",
        "\n",
        "      data = { \n",
        "          'id': id,\n",
        "          'text': doc,\n",
        "          'POS tags': pos_tag_vec,\n",
        "          'Arg tags': arg_tag_vec\n",
        "          }\n",
        "      \n",
        "      try: \n",
        "        fi = open(f'{path}/dataset.csv', 'a')\n",
        "        writer = csv.writer(fi, delimiter=',',lineterminator='\\n')\n",
        "        row = [id , doc, ' '.join(map(str,pos_tag_vec)),' '.join(map(str,arg_tag_vec))]\n",
        "        writer.writerow(row)\n",
        "        fi.close()\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "\n",
        "  dataset = pd.read_csv(f'{path}/dataset.csv')\n",
        "        \n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxxZbdl57qEs"
      },
      "outputs": [],
      "source": [
        "#dataset= create_dataset(emmbed_dim=50, max_words=max_seq_length)\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/PFA/dataset.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "mbnwMNCmUh8I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07ed907f-d8ba-446a-fd37-ea874c46303d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 15594 entries, 0 to 15593\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      15594 non-null  object\n",
            " 1   text    15594 non-null  object\n",
            " 2   pos     15594 non-null  object\n",
            " 3   arg     15594 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 487.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts([text for text in dataset['text'].values])\n",
        "vocab_size = len(t.word_index)+1"
      ],
      "metadata": {
        "id": "XL9o4VqOxheq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "bsM3FDce1Kzn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48753dcd-9ead-4795-f394-14db09a6bd94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "67888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "X = dataset['text'].values\n",
        "y = dataset['arg'].values\n",
        "\n",
        "y=[np.array([float(x1) for x1 in x.split()]) for x in y]\n",
        "\n",
        "X_encode = t.texts_to_sequences(X)\n",
        "X_padded = pad_sequences(X_encode, maxlen=max_seq_length,padding='post')\n",
        "y_padded = pad_sequences(y, maxlen=max_seq_length,padding='post')\n"
      ],
      "metadata": {
        "id": "8eJWNibmPj5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_padded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZaDqGsbSlqP",
        "outputId": "9e275b1c-7d97-4c3b-ff68-6da969e53094"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15594, 500)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "y_cat = np_utils.to_categorical(y_padded)"
      ],
      "metadata": {
        "id": "inVNkvHqPspg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSniU688PMCh"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded,y_cat, test_size=0.2, random_state=42 )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix = np.zeros((vocab_size,50))\n",
        "for word, i in t.word_index.items():\n",
        "\tembedding_vector = embeddings_index.get(word)\n",
        "\tif embedding_vector is not None:\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "metadata": {
        "id": "9ngwPHaI22fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmSVrD0T_MNg"
      },
      "outputs": [],
      "source": [
        "from keras import Sequential\n",
        "\n",
        "def modelLSTM(input_length,internal_units,output_size,vocab_size,embedding_matrix=embedding_matrix,embedding_dim=50):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size,embedding_dim,weights=[embedding_matrix],input_length=input_length,trainable=False))\n",
        "    model.add(layers.LSTM(input_length=50,units=internal_units,return_sequences=True))\n",
        "    #model.add(layers.Flatten()) \n",
        "    model.add(layers.TimeDistributed(layers.Dense(output_size,activation='softmax')))\n",
        "    return model\n",
        "\n",
        "\n",
        "def loss_function(y_true,y_pred):\n",
        "  return sum(np.float32(y_true)-np.float32(y_pred))/len(np.float32(y_true))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = modelLSTM(input_length=max_seq_length,internal_units=64,output_size=y_test.shape[2],vocab_size=vocab_size)\n",
        "model.build()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "RQvV9O_8qPa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b938382a-b634-40cc-f70c-7e43091cbf1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 500, 50)           3394400   \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 500, 64)           29440     \n",
            "                                                                 \n",
            " time_distributed (TimeDistr  (None, 500, 8)           520       \n",
            " ibuted)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,424,360\n",
            "Trainable params: 29,960\n",
            "Non-trainable params: 3,394,400\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy'])\n",
        "history=model.fit(x=X_train, y=y_train, batch_size=256, epochs=10, validation_data=(X_test, y_test), verbose=1)\n",
        "loss, accuracy = model.evaluate(X_test,  y_test, verbose=1)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "7ygnY8FVroa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b06236d7-eb36-4e9e-a9e3-476c8cb20e48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "49/49 [==============================] - 10s 46ms/step - loss: 1.4480 - categorical_accuracy: 0.6451 - val_loss: 1.1165 - val_categorical_accuracy: 0.6518\n",
            "Epoch 2/10\n",
            "49/49 [==============================] - 2s 33ms/step - loss: 1.0647 - categorical_accuracy: 0.6621 - val_loss: 0.9896 - val_categorical_accuracy: 0.6851\n",
            "Epoch 3/10\n",
            "49/49 [==============================] - 2s 35ms/step - loss: 0.9391 - categorical_accuracy: 0.6935 - val_loss: 0.9072 - val_categorical_accuracy: 0.6974\n",
            "Epoch 4/10\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.8917 - categorical_accuracy: 0.7010 - val_loss: 0.8889 - val_categorical_accuracy: 0.6987\n",
            "Epoch 5/10\n",
            "49/49 [==============================] - 2s 36ms/step - loss: 0.8756 - categorical_accuracy: 0.7040 - val_loss: 0.8839 - val_categorical_accuracy: 0.7020\n",
            "Epoch 6/10\n",
            "49/49 [==============================] - 2s 35ms/step - loss: 0.8616 - categorical_accuracy: 0.7090 - val_loss: 0.8568 - val_categorical_accuracy: 0.7096\n",
            "Epoch 7/10\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.8492 - categorical_accuracy: 0.7132 - val_loss: 0.8551 - val_categorical_accuracy: 0.7109\n",
            "Epoch 8/10\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.8417 - categorical_accuracy: 0.7162 - val_loss: 0.8413 - val_categorical_accuracy: 0.7151\n",
            "Epoch 9/10\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.8415 - categorical_accuracy: 0.7160 - val_loss: 0.8447 - val_categorical_accuracy: 0.7115\n",
            "Epoch 10/10\n",
            "49/49 [==============================] - 2s 34ms/step - loss: 0.8329 - categorical_accuracy: 0.7186 - val_loss: 0.8320 - val_categorical_accuracy: 0.7189\n",
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8320 - categorical_accuracy: 0.7189\n",
            "Accuracy: 71.892786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test,  y_test, verbose=1)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ],
      "metadata": {
        "id": "6EEVYQaKfXSG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bc625b1-3678-40b9-f471-99a673b175b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "98/98 [==============================] - 1s 8ms/step - loss: 0.8320 - categorical_accuracy: 0.7189\n",
            "Accuracy: 71.892786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, f1_score\n",
        "ydl_pred = np.argmax(model.predict(X_test), axis=-1)\n",
        "y_true = np.argmax(y_test,axis=-1)"
      ],
      "metadata": {
        "id": "jhRRUZhFofFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=[ f1_score(y_t,y_p,average='weighted') for y_t,y_p in zip(y_true,ydl_pred)]"
      ],
      "metadata": {
        "id": "gITvklaHHoXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.mean(cm)"
      ],
      "metadata": {
        "id": "kjA3dWGlOwBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "083fd7f3-d5fd-44df-e133-1305fb11f802"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6726880606845136"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import numpy\n",
        "numpy.set_printoptions(threshold=sys.maxsize)"
      ],
      "metadata": {
        "id": "OkbVGAgkSH77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ydl_pred[0])"
      ],
      "metadata": {
        "id": "0RF5CSznO2ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19e31dc5-015f-4401-b254-86b562222b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 4 4 4 4 4 4 4 4 4 4 4 2 4 4 4 4 4 4\n",
            " 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 3 4 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
            " 3 3 3 3 3 3 3 5 5 3 3 3 3 3 3 3 3 5 5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true[0]"
      ],
      "metadata": {
        "id": "R4Eo8h6fRkOJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108d4a42-0b82-40b7-be72-3f3a4a798964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
              "       3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def modelLSTM1(input_length,internal_units,output_size,vocab_size,embedding_matrix=embedding_matrix,embedding_dim=50):\n",
        "    model = Sequential()\n",
        "    model.add(layers.Embedding(vocab_size,embedding_dim,weights=[embedding_matrix],input_length=input_length,trainable=False))\n",
        "    model.add(layers.LSTM(input_length=50,units=internal_units,return_sequences=True))\n",
        "    #model.add(layers.Flatten()) \n",
        "    model.add(layers.TimeDistributed(layers.Dense(output_size,activation='softmax')))\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "E6WOyEW1M76T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r /content/drive/MyDrive/PFA/treated-data"
      ],
      "metadata": {
        "id": "mQb48LWJWLKV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/drive/MyDrive/PFA/treated-data ; cp /content/data/train/* /content/drive/MyDrive/PFA/treated-data"
      ],
      "metadata": {
        "id": "c3aTO8DtgdSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WN6JVDXlXjHK"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "LSTM w/o pos.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}